# ğŸŒ¿ Plant Pathology Project â€” CSI Internship

This folder in the repository contains the **image classification project** assigned for the Plant Pathology task, which focuses on classifying leaf images into multiple disease categories using **traditional machine learning techniques** (not deep learning or transfer learning).

---

## ğŸ¯ **Project Objective**

To classify leaf images into **four categories** â€” **Healthy**, **Rust**, **Scab**, and **Multiple Diseases** â€” using **handcrafted features** and traditional ML models.

---

## ğŸ—‚ï¸ **Dataset Description**

- Images of plant leaves with different conditions (healthy or infected).
- Each image has a **unique `image_id`** and a **label**.
- **Classes:**
  - Healthy (516 images)
  - Rust (622 images)
  - Scab (592 images)
  - Multiple Diseases (91 images)
- Images are stored in: `images_plant_pathology/`
- Labels are linked via: `plant_pathology_project.csv`

---

## ğŸ” **Features Extracted**

- ğŸ“Š **Color Histograms:**  
  - 8 bins each for **Blue**, **Green**, **Red** channels â†’ 24 features total.
- ğŸŒ€ **Texture (LBP):**  
  - Local Binary Pattern histograms â†’ 9 features.
- ğŸ§© **Texture (GLCM):**  
  - Haralick Gray-Level Co-occurrence Matrix â†’ **Contrast** & **Dissimilarity** (2 features).

---

## âš™ï¸ **Models Used**

- ğŸŒ² **Random Forest**
- ğŸ¯ **Gradient Boosting**
- ğŸ§© **Support Vector Machine (SVM)**
- âš¡ **XGBoost** (for comparison)

---

## ğŸ§ª **Model Training & Evaluation**

- Data split into **training** and **validation** sets.
- **GridSearchCV** used for tuning hyperparameters.
- **Metrics:**  
  - Validation Accuracy  
  - Confusion Matrix  
  - Classification Report (Precision, Recall, F1-Score)
- Models also tested on **random validation images** to visually confirm predictions.

---

## ğŸ“Š **Outcome**

- âœ… **Gradient Boosting** achieved **~61% accuracy**.
- âœ… **Random Forest & XGBoost**: **~58â€“59% accuracy**.
- âœ… **SVM**: ~58% accuracy.
- Note: Accuracy is lower than deep learning as **traditional ML uses manual features**.

---

## âš ï¸ **Limitations**

- ğŸ“Œ **No use of test images:** Official test images had no ground truth labels (Kaggle-only).
- ğŸ“Œ Accuracy can be significantly improved with **deep learning (CNNs)** and **transfer learning**.
- ğŸ“Œ Traditionsl ML and Handcrafted features have limitations in capturing complex patterns.

---

## ğŸš€ **Deployment**

The best performing **Gradient Boosting model** is deployed using **Streamlit**:

ğŸ‘‰ [**View the Live App Here**](https://imageclassificationcsi25internthirdyear-o8tovuycmczd8tzrwvjpu6.streamlit.app/)

---

## ğŸ› ï¸ **Tools & Libraries**

- **Python**
- **OpenCV** (image reading & processing)
- **Scikit-image** (LBP & GLCM texture)
- **Scikit-learn** (models, GridSearchCV, metrics)
- **XGBoost**
- **Matplotlib & Seaborn** (visualization)
- **Streamlit** (deployment)

---

âœ¨ *This project demonstrates how classic ML pipelines can be built for image classification with handcrafted features in a resource-constrained setting.*  



